#!/usr/bin/env python3
"""
üïµÔ∏è ROOT CAUSE DETECTIVE AGENT
AI Agent for News ‚Üí Price correlation analysis and market-moving event detection
"""

import asyncio
import json
import sqlite3
import time
import requests
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from pathlib import Path
import os
import logging
import re
from dataclasses import dataclass

@dataclass
class NewsEvent:
    title: str
    content: str
    source: str
    timestamp: datetime
    sentiment_score: float
    impact_prediction: float
    keywords: List[str]
    market_correlation: float

@dataclass
class CorrelationPattern:
    event_type: str
    price_impact: float
    time_delay: int  # minutes
    confidence: float
    historical_accuracy: float
    pattern_strength: float

class RootCauseDetectiveAgent:
    """
    AI Agent for discovering root causes of price movements
    - News ‚Üí Price correlation analysis
    - Market-moving event identification
    - Predictive impact scoring
    - Newsletter intelligence extraction
    """
    
    def __init__(self):
        self.agent_id = "root_cause_detective_001"
        self.db_path = "data/root_cause_analysis.db"
        self.setup_database()
        self.setup_logging()
        
        # Agent parameters
        self.analysis_window = 24  # hours
        self.correlation_threshold = 0.3
        self.impact_threshold = 0.05  # 5% price movement
        
        # Market-moving keywords with impact weights
        self.impact_keywords = {
            "regulatory": {
                "keywords": ["regulation", "sec", "ban", "legal", "court", "fine"],
                "impact_weight": 0.8,
                "typical_delay": 15  # minutes
            },
            "institutional": {
                "keywords": ["etf", "institutional", "fund", "investment", "adoption"],
                "impact_weight": 0.7,
                "typical_delay": 30
            },
            "technical": {
                "keywords": ["hack", "bug", "security", "upgrade", "fork"],
                "impact_weight": 0.9,
                "typical_delay": 5
            },
            "macroeconomic": {
                "keywords": ["fed", "interest", "inflation", "recession", "stimulus"],
                "impact_weight": 0.6,
                "typical_delay": 60
            },
            "celebrity": {
                "keywords": ["elon", "musk", "saylor", "tesla", "microstrategy"],
                "impact_weight": 0.8,
                "typical_delay": 10
            }
        }
        
        # Historical correlation patterns
        self.correlation_patterns = {}
        self.load_historical_patterns()
        
    def setup_database(self):
        """Setup correlation analysis database"""
        Path("data").mkdir(exist_ok=True)
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # News events table
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS news_events (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp REAL NOT NULL,
                title TEXT NOT NULL,
                content TEXT NOT NULL,
                source TEXT NOT NULL,
                sentiment_score REAL DEFAULT 0.0,
                impact_prediction REAL DEFAULT 0.0,
                keywords TEXT,
                market_correlation REAL DEFAULT 0.0
            )
        """)
        
        # Correlation patterns table
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS correlation_patterns (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                event_type TEXT NOT NULL,
                keyword_pattern TEXT NOT NULL,
                average_impact REAL NOT NULL,
                average_delay INTEGER NOT NULL,
                confidence_score REAL NOT NULL,
                accuracy_rate REAL NOT NULL,
                sample_size INTEGER NOT NULL,
                last_updated REAL NOT NULL
            )
        """)
        
        conn.commit()
        conn.close()
        
    def setup_logging(self):
        """Setup agent logging"""
        Path("logs").mkdir(exist_ok=True)
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - RootCauseDetective - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('logs/root_cause_detective.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        self.logger.info(f"üïµÔ∏è Root Cause Detective Agent {self.agent_id} initialized")
    
    async def run_correlation_analysis(self) -> Dict[str, Any]:
        """Alias for test compatibility"""
        return await self.run_analysis_cycle()
    
    async def run_analysis_cycle(self) -> Dict[str, Any]:
        """Run comprehensive root cause analysis cycle"""
        self.logger.info("üîç Starting root cause analysis cycle...")
        cycle_start = time.time()
        
        # 1. Collect recent news events
        news_events = await self.collect_recent_news()
        
        # 2. Analyze market-moving potential
        analyzed_events = await self.analyze_market_impact(news_events)
        
        # 3. Identify correlation patterns
        correlations = await self.identify_correlations()
        
        # 4. Generate predictive insights
        predictions = await self.generate_predictions(analyzed_events)
        
        cycle_time = time.time() - cycle_start
        
        results = {
            "cycle_time": cycle_time,
            "news_events_analyzed": len(news_events),
            "high_impact_events": len([e for e in analyzed_events if e.impact_prediction > 0.7]),
            "correlations_found": len(correlations),
            "predictions_generated": len(predictions),
            "top_events": [
                {
                    "title": event.title[:100],
                    "impact_prediction": event.impact_prediction,
                    "correlation": event.market_correlation,
                    "keywords": event.keywords[:5]
                } for event in analyzed_events[:5]
            ],
            "strongest_correlations": [
                {
                    "pattern": corr.event_type,
                    "impact": corr.price_impact,
                    "confidence": corr.confidence
                } for corr in correlations[:3]
            ]
        }
        
        self.logger.info(f"‚úÖ Root cause analysis complete ({cycle_time:.2f}s)")
        self.logger.info(f"   üìä News events analyzed: {len(news_events)}")
        self.logger.info(f"   üö® High-impact events: {len([e for e in analyzed_events if e.impact_prediction > 0.7])}")
        self.logger.info(f"   üîó Correlations found: {len(correlations)}")
        
        return results
    
    async def collect_recent_news(self) -> List[NewsEvent]:
        """Collect recent news from enhanced sources"""
        news_events = []
        
        # Get from enhanced news database
        try:
            conn = sqlite3.connect("data/enhanced_sources_data.db")
            cursor = conn.cursor()
            
            # Get recent news (last 24 hours)
            recent_news = cursor.execute("""
                SELECT source_name, title, content, timestamp, sentiment_score, impact_prediction
                FROM enhanced_news 
                WHERE timestamp > ?
                ORDER BY timestamp DESC
                LIMIT 50
            """, (time.time() - 86400,)).fetchall()
            
            conn.close()
            
            for news in recent_news:
                source, title, content, timestamp, sentiment, impact = news
                
                # Extract keywords
                keywords = self.extract_keywords(title + " " + content)
                
                # Calculate market correlation
                correlation = self.calculate_market_correlation(keywords, sentiment)
                
                event = NewsEvent(
                    title=title,
                    content=content,
                    source=source,
                    timestamp=datetime.fromtimestamp(timestamp),
                    sentiment_score=sentiment,
                    impact_prediction=impact,
                    keywords=keywords,
                    market_correlation=correlation
                )
                
                news_events.append(event)
                
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Error collecting news: {e}")
            # Generate mock data for testing
            news_events = self.generate_mock_news_events()
        
        return news_events
    
    async def analyze_market_impact(self, news_events: List[NewsEvent]) -> List[NewsEvent]:
        """Analyze potential market impact of news events"""
        analyzed_events = []
        
        for event in news_events:
            # Enhanced impact analysis
            enhanced_impact = await self.calculate_enhanced_impact(event)
            
            # Update impact prediction
            event.impact_prediction = enhanced_impact
            
            # Store analyzed event
            self.store_news_event(event)
            analyzed_events.append(event)
        
        # Sort by impact prediction
        analyzed_events.sort(key=lambda x: x.impact_prediction, reverse=True)
        
        return analyzed_events
    
    async def calculate_enhanced_impact(self, event: NewsEvent) -> float:
        """Calculate enhanced market impact prediction"""
        impact_score = 0.0
        
        # 1. Keyword-based impact
        for category, data in self.impact_keywords.items():
            keyword_matches = sum(1 for keyword in data["keywords"] 
                                if keyword.lower() in event.title.lower() or 
                                   keyword.lower() in event.content.lower())
            if keyword_matches > 0:
                impact_score += data["impact_weight"] * (keyword_matches / len(data["keywords"]))
        
        # 2. Sentiment amplification
        impact_score *= (1 + abs(event.sentiment_score))
        
        # 3. Source credibility weight
        source_weights = {
            "coindesk": 0.9,
            "cointelegraph": 0.8,
            "reuters": 1.0,
            "sec.gov": 1.0,
            "twitter": 0.6
        }
        
        source_weight = 0.7  # default
        for source, weight in source_weights.items():
            if source in event.source.lower():
                source_weight = weight
                break
        
        impact_score *= source_weight
        
        # 4. Historical pattern matching
        historical_impact = self.get_historical_impact(event.keywords)
        impact_score = (impact_score + historical_impact) / 2
        
        # Normalize to 0-1 scale
        return min(impact_score, 1.0)
    
    async def identify_correlations(self) -> List[CorrelationPattern]:
        """Identify news-price correlation patterns"""
        correlations = []
        
        # Generate mock correlations for testing
        correlations = [
            CorrelationPattern("regulatory", -0.12, 25, 0.8, 0.75, 0.9),
            CorrelationPattern("institutional", 0.08, 45, 0.7, 0.65, 0.8),
            CorrelationPattern("celebrity", 0.15, 12, 0.9, 0.85, 0.95)
        ]
        
        return correlations
    
    async def generate_predictions(self, events: List[NewsEvent]) -> List[Dict[str, Any]]:
        """Generate market movement predictions based on news"""
        predictions = []
        
        for event in events:
            if event.impact_prediction > 0.5:  # Only high-impact events
                # Find similar historical patterns
                similar_patterns = self.find_similar_patterns(event)
                
                if similar_patterns:
                    avg_impact = sum(p.price_impact for p in similar_patterns) / len(similar_patterns)
                    avg_delay = sum(p.time_delay for p in similar_patterns) / len(similar_patterns)
                    confidence = sum(p.confidence for p in similar_patterns) / len(similar_patterns)
                    
                    prediction = {
                        "event_title": event.title[:100],
                        "predicted_impact": avg_impact,
                        "expected_delay_minutes": int(avg_delay),
                        "confidence": confidence,
                        "reasoning": f"Based on {len(similar_patterns)} similar historical events",
                        "keywords": event.keywords[:3],
                        "recommendation": self.generate_recommendation(avg_impact, confidence)
                    }
                    
                    predictions.append(prediction)
        
        return predictions
    
    # Helper methods
    def extract_keywords(self, text: str) -> List[str]:
        """Extract important keywords from text"""
        # Combine all impact keywords
        all_keywords = []
        for category_data in self.impact_keywords.values():
            all_keywords.extend(category_data["keywords"])
        
        # Find matches in text
        found_keywords = []
        text_lower = text.lower()
        for keyword in all_keywords:
            if keyword in text_lower:
                found_keywords.append(keyword)
        
        # Add additional important words
        important_words = ["bitcoin", "ethereum", "crypto", "price", "surge", "crash", "rally"]
        for word in important_words:
            if word in text_lower and word not in found_keywords:
                found_keywords.append(word)
        
        return found_keywords[:10]  # Limit to top 10
    
    def calculate_market_correlation(self, keywords: List[str], sentiment: float) -> float:
        """Calculate potential market correlation"""
        correlation = 0.0
        
        # Keyword-based correlation
        for keyword in keywords:
            for category_data in self.impact_keywords.values():
                if keyword in category_data["keywords"]:
                    correlation += category_data["impact_weight"] * 0.1
        
        # Sentiment influence
        correlation *= (1 + abs(sentiment))
        
        return min(correlation, 1.0)
    
    def get_historical_impact(self, keywords: List[str]) -> float:
        """Get historical impact for similar keywords"""
        # Simplified - would check historical database
        if any(word in ["regulation", "sec", "ban"] for word in keywords):
            return 0.8
        elif any(word in ["adoption", "etf", "institutional"] for word in keywords):
            return 0.7
        elif any(word in ["elon", "musk", "tesla"] for word in keywords):
            return 0.9
        else:
            return 0.5
    
    def classify_event_type(self, keywords_str: str) -> str:
        """Classify event type based on keywords"""
        if any(word in keywords_str for word in ["regulation", "sec", "ban"]):
            return "regulatory"
        elif any(word in keywords_str for word in ["etf", "institutional"]):
            return "institutional"
        elif any(word in keywords_str for word in ["hack", "security"]):
            return "technical"
        elif any(word in keywords_str for word in ["elon", "musk"]):
            return "celebrity"
        else:
            return "general"
    
    def find_similar_patterns(self, event: NewsEvent) -> List[CorrelationPattern]:
        """Find similar historical patterns"""
        # Simplified - would do sophisticated pattern matching
        similar = []
        
        event_type = self.classify_event_type(str(event.keywords))
        
        # Mock similar patterns based on event type
        if event_type == "regulatory":
            similar.append(CorrelationPattern("regulatory", -0.15, 30, 0.8, 0.7, 0.9))
        elif event_type == "institutional":
            similar.append(CorrelationPattern("institutional", 0.08, 60, 0.7, 0.6, 0.8))
        elif event_type == "celebrity":
            similar.append(CorrelationPattern("celebrity", 0.12, 15, 0.9, 0.8, 0.9))
        
        return similar
    
    def generate_recommendation(self, impact: float, confidence: float) -> str:
        """Generate trading recommendation"""
        if confidence < 0.5:
            return "Monitor situation - low confidence"
        elif impact > 0.1:
            return "Potential buying opportunity - positive impact expected"
        elif impact < -0.1:
            return "Consider risk management - negative impact expected"
        else:
            return "Minimal market impact expected"
    
    def store_news_event(self, event: NewsEvent):
        """Store news event in database"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            INSERT INTO news_events
            (timestamp, title, content, source, sentiment_score, impact_prediction, 
             keywords, market_correlation)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            event.timestamp.timestamp(),
            event.title,
            event.content,
            event.source,
            event.sentiment_score,
            event.impact_prediction,
            json.dumps(event.keywords),
            event.market_correlation
        ))
        
        conn.commit()
        conn.close()
    
    def load_historical_patterns(self):
        """Load historical correlation patterns"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            patterns = cursor.execute("""
                SELECT event_type, average_impact, average_delay, confidence_score
                FROM correlation_patterns
                WHERE confidence_score > 0.6
            """).fetchall()
            
            for pattern in patterns:
                event_type, impact, delay, confidence = pattern
                self.correlation_patterns[event_type] = {
                    "impact": impact,
                    "delay": delay,
                    "confidence": confidence
                }
            
            conn.close()
            
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Could not load historical patterns: {e}")
    
    def generate_mock_news_events(self) -> List[NewsEvent]:
        """Generate mock news events for testing"""
        return [
            NewsEvent(
                title="SEC Approves Bitcoin ETF Application",
                content="The Securities and Exchange Commission has approved the first Bitcoin ETF",
                source="reuters",
                timestamp=datetime.now(),
                sentiment_score=0.8,
                impact_prediction=0.9,
                keywords=["sec", "etf", "bitcoin", "approval"],
                market_correlation=0.85
            ),
            NewsEvent(
                title="Major Exchange Reports Security Breach",
                content="Large cryptocurrency exchange reports unauthorized access",
                source="coindesk",
                timestamp=datetime.now(),
                sentiment_score=-0.7,
                impact_prediction=0.8,
                keywords=["security", "breach", "exchange", "hack"],
                market_correlation=0.75
            ),
            NewsEvent(
                title="Elon Musk Tweets About Bitcoin",
                content="Tesla CEO mentions Bitcoin in latest social media post",
                source="twitter",
                timestamp=datetime.now(),
                sentiment_score=0.6,
                impact_prediction=0.8,
                keywords=["elon", "musk", "bitcoin", "tesla"],
                market_correlation=0.8
            )
        ]

if __name__ == "__main__":
    async def main():
        agent = RootCauseDetectiveAgent()
        
        print("üïµÔ∏è Root Cause Detective Agent - Running analysis cycle...")
        
        # Run analysis cycle
        results = await agent.run_analysis_cycle()
        
        print(f"\nüéØ ANALYSIS RESULTS:")
        print(f"Cycle Time: {results['cycle_time']:.2f}s")
        print(f"News Events Analyzed: {results['news_events_analyzed']}")
        print(f"High-Impact Events: {results['high_impact_events']}")
        print(f"Correlations Found: {results['correlations_found']}")
        print(f"Predictions Generated: {results['predictions_generated']}")
        
        if results['top_events']:
            print(f"\nüì∞ TOP IMPACT EVENTS:")
            for event in results['top_events']:
                print(f"  {event['title']}")
                print(f"    Impact: {event['impact_prediction']:.2f}, Keywords: {event['keywords']}")
        
        if results['strongest_correlations']:
            print(f"\nüîó STRONGEST CORRELATIONS:")
            for corr in results['strongest_correlations']:
                print(f"  {corr['pattern']}: {corr['impact']:.2f} impact ({corr['confidence']:.2f} confidence)")
    
    asyncio.run(main()) 